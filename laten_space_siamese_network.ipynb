{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPmU8qKHoQeOM8j7V5haWeE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashishsaini01/Anomaly_detection_using_autoencoders/blob/main/laten_space_siamese_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DD6L5YIxoAQG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as k\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import cv2\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "from skimage.feature import hog\n",
        "from skimage import color"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mounting google drive for easy data reading\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1gYjJPUoJZa",
        "outputId": "f9cabe83-fd54-4f74-e6b0-cf2602e7d58e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.load('/content/drive/MyDrive/light_on_0.npz')\n",
        "# print(data.files)\n",
        "x, g, tx, ty, i, gi, ti = data['x'], data['gx'], data['tx'], data['tn'], data['i'], data['gi'], data['ti']"
      ],
      "metadata": {
        "id": "_6qR3G-loLMX"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape, g.shape, tx.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AF4uZzEAoN_Z",
        "outputId": "e2e8d7b6-f472-46cd-a45f-c6e315d52ced"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1500, 128, 384, 3), (101, 128, 384, 3), (404, 128, 384, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize\n",
        "x_norm = x/255\n",
        "g_norm = g/255\n",
        "tx_norm = tx/255"
      ],
      "metadata": {
        "id": "GU3V1eMy7ehN"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoding_dim = 128\n",
        "input_img = tf.keras.layers.Input(shape = x_norm.shape[1:]) # input layer\n",
        "\n",
        "# encoder\n",
        "encoded = tf.keras.layers.Conv2D(encoding_dim, kernel_size = (5, 5), padding = 'same', strides = 2,  activation = 'relu')(input_img)\n",
        "encoded = tf.keras.layers.Conv2D(encoding_dim, kernel_size = (3, 3), padding = 'same', activation = 'relu')(encoded)\n",
        "encoded = tf.keras.layers.MaxPool2D(pool_size = (2, 2),)(encoded)\n",
        "encoded = tf.keras.layers.Conv2D(encoding_dim/2, kernel_size = (3, 3), padding = 'same', activation = 'relu')(encoded)\n",
        "#encoded = tf.keras.layers.MaxPool2D(pool_size = (2, 2),)(encoded)\n",
        "encoded = tf.keras.layers.Conv2D(encoding_dim/4, kernel_size = (3, 3), padding = 'same', activation = 'relu')(encoded)\n",
        "encoded = tf.keras.layers.Conv2D(encoding_dim/8, kernel_size = (3, 3), padding = 'same', activation = 'relu')(encoded)\n",
        "encoded = tf.keras.layers.Conv2D(3, kernel_size = (3, 3), padding = 'same', activation = 'relu')(encoded)\n",
        "\n",
        "encoder = tf.keras.Model(input_img, encoded) # this maps an input to it's encoded representation"
      ],
      "metadata": {
        "id": "UHO1_TGWwKD9"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# latent representaion of x, g, tx\n",
        "x_latent = encoder.predict(x_norm)\n",
        "g_latent = encoder.predict(g_norm)\n",
        "tx_latent = encoder.predict(tx_norm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLZJNPIj-lHJ",
        "outputId": "8d361583-3d88-4f72-bc17-00c3f99eef9f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47/47 [==============================] - 1s 23ms/step\n",
            "4/4 [==============================] - 0s 25ms/step\n",
            "13/13 [==============================] - 0s 24ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# saving encoded representation\n",
        "np.savez_compressed(\"/content/drive/MyDrive/light_on_latent_0.npz\", x_latent = x_latent, g_latent = g_latent, tx_latent = tx_latent, ty = ty, i = i, gi = gi, ti = ti)"
      ],
      "metadata": {
        "id": "uxy_55oyHCM5"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.load('/content/drive/MyDrive/light_on_latent_0.npz')\n",
        "# print(data.files)\n",
        "x_latent, g_latent, tx_latent, ty, i, gi, ti = data['x_latent'], data['g_latent'], data['tx_latent'], data['ty'], data['i'], data['gi'], data['ti']"
      ],
      "metadata": {
        "id": "Gd_ZVcaMJ7Uh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_latent.shape, g_latent.shape, tx_latent.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MNxGaS6-22x",
        "outputId": "8eb21171-2325-4b49-84c4-4cf8eeb5c2c2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1500, 32, 96, 3), (101, 32, 96, 3), (404, 32, 96, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training siamene network on encoded representation of input"
      ],
      "metadata": {
        "id": "aJHhq3fOBg1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating batchs for traning (anchor, positive, and, negative (for triplet loss))\n",
        "def create_batch(batch_size=500):\n",
        "    x_anchors = np.zeros((batch_size, 32, 96, 3))\n",
        "    x_positives = np.zeros((batch_size, 32, 96, 3))\n",
        "    x_negatives = np.zeros((batch_size, 32, 96, 3))\n",
        "    \n",
        "    for j in range(0, batch_size):\n",
        "        # We need to find an anchor, a positive example and a negative example\n",
        "        random_index = random.randint(0, x_latent.shape[0] - 1)\n",
        "        x_anchor = x_latent[random_index]\n",
        "\n",
        "        pos_index = random.randint(0, x_latent.shape[0] - 1)\n",
        "\n",
        "        while pos_index == random_index or i[pos_index] != i[random_index]:\n",
        "          pos_index = random.randint(0, x_latent.shape[0] - 1)\n",
        "\n",
        "        x_positive = x_latent[pos_index]  # also for the same pallet block\n",
        "        \n",
        "        random_index_neg = random.randint(0, x_latent.shape[0] - 1)\n",
        "\n",
        "        while random_index_neg == random_index or i[random_index] == i[random_index_neg]:\n",
        "          random_index_neg = random.randint(0, x_latent.shape[0] - 1)\n",
        "         \n",
        "        x_negative = x_latent[random_index_neg]\n",
        "        \n",
        "        x_anchors[j] = x_anchor\n",
        "        x_positives[j] = x_positive\n",
        "        x_negatives[j] = x_negative\n",
        "        \n",
        "    x_anchors = np.expand_dims(x_anchors, axis = 1)\n",
        "    x_positives = np.expand_dims(x_positives, axis = 1)\n",
        "    x_negatives = np.expand_dims(x_negatives, axis = 1)\n",
        "\n",
        "    k_con = np.concatenate([x_anchors, x_positives, x_negatives], axis = 1)\n",
        "        \n",
        "    return k_con"
      ],
      "metadata": {
        "id": "NeQOddhT-7E5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# embeding model\n",
        "emb_size = 64\n",
        "\n",
        "embedding_model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(emb_size, kernel_size = (5, 5), strides = 2, padding = 'same', activation = 'relu', input_shape = (32, 96, 3)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(emb_size, kernel_size = (3, 3), padding = 'same', activation = 'relu'),\n",
        "    tf.keras.layers.MaxPool2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(emb_size/2, kernel_size = (3, 3), padding = 'same', activation = 'relu'),\n",
        "    tf.keras.layers.MaxPool2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(emb_size/4, kernel_size = (3, 3), padding = 'same', activation = 'relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(emb_size/4, kernel_size = (3, 3), padding = 'same', activation = 'relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation = 'relu'),\n",
        "    tf.keras.layers.Dense(128, activation = 'relu'),\n",
        "    tf.keras.layers.Dense(30)\n",
        "])\n",
        "\n",
        "embedding_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bus44J6pBfTE",
        "outputId": "3bbb2f08-9072-4e4e-d282-81fb4be25455"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 16, 48, 64)        4864      \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 16, 48, 64)       256       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 16, 48, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 8, 24, 64)        0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 8, 24, 64)        256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 8, 24, 32)         18464     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 4, 12, 32)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 4, 12, 32)        128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 4, 12, 16)         4624      \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 4, 12, 16)        64        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 4, 12, 16)         2320      \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 4, 12, 16)        64        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 4, 12, 16)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 768)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               98432     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 30)                3870      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 186,782\n",
            "Trainable params: 186,398\n",
            "Non-trainable params: 384\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# siamese network\n",
        "siamese_input = tf.keras.Input(shape = (3, 32, 96, 3))\n",
        "input_anchor =  siamese_input[:, 0]                                              #tf.keras.layers.Input(shape=(32, 96, 3))\n",
        "input_positive = siamese_input[:, 1]                                             #tf.keras.layers.Input(shape=(32, 96, 3))\n",
        "input_negative = siamese_input[:, 2]                                             #tf.keras.layers.Input(shape=(32, 96, 3))\n",
        "\n",
        "embedding_anchor = embedding_model(input_anchor)\n",
        "embedding_positive = embedding_model(input_positive)\n",
        "embedding_negative = embedding_model(input_negative)\n",
        "\n",
        "embedding_anchor = k.expand_dims(embedding_anchor, 1)\n",
        "embedding_negative = k.expand_dims(embedding_negative, 1)\n",
        "embedding_positive = k.expand_dims(embedding_positive, 1)\n",
        "\n",
        "\n",
        "output = tf.keras.layers.concatenate([embedding_anchor, embedding_positive, embedding_negative], axis=1) \n",
        "\n",
        "model = tf.keras.models.Model(siamese_input, output)\n",
        "model.summary()\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bACfws5MGk8X",
        "outputId": "fd241ba6-f850-44fb-e21e-83f08847a67b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 3, 32, 96,   0           []                               \n",
            "                                3)]                                                               \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (Slic  (None, 32, 96, 3)   0           ['input_1[0][0]']                \n",
            " ingOpLambda)                                                                                     \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_1 (Sl  (None, 32, 96, 3)   0           ['input_1[0][0]']                \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_2 (Sl  (None, 32, 96, 3)   0           ['input_1[0][0]']                \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " sequential (Sequential)        (None, 30)           186782      ['tf.__operators__.getitem[0][0]'\n",
            "                                                                 , 'tf.__operators__.getitem_1[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'tf.__operators__.getitem_2[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " tf.expand_dims (TFOpLambda)    (None, 1, 30)        0           ['sequential[0][0]']             \n",
            "                                                                                                  \n",
            " tf.expand_dims_2 (TFOpLambda)  (None, 1, 30)        0           ['sequential[1][0]']             \n",
            "                                                                                                  \n",
            " tf.expand_dims_1 (TFOpLambda)  (None, 1, 30)        0           ['sequential[2][0]']             \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 3, 30)        0           ['tf.expand_dims[0][0]',         \n",
            "                                                                  'tf.expand_dims_2[0][0]',       \n",
            "                                                                  'tf.expand_dims_1[0][0]']       \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 186,782\n",
            "Trainable params: 186,398\n",
            "Non-trainable params: 384\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = 0.05\n",
        "\n",
        "pos = k.mean((embedding_anchor - embedding_positive)**2, axis = 1)\n",
        "neg = k.mean((embedding_anchor - embedding_negative)**2, axis = 1)\n",
        "\n",
        "loss = k.mean(k.relu(pos - neg + alpha)) "
      ],
      "metadata": {
        "id": "0AK42G2dIM-Y"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 7000\n",
        "x_train = create_batch(batch_size)\n",
        "x_train = np.array(x_train)\n",
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oSDa664JIgA",
        "outputId": "087489a0-5f20-4759-f410-ca580eab6436"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7000, 3, 32, 96, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# batch_size = 2048\n",
        "epochs = 25\n",
        "# steps_per_epoch = 25\n",
        "\n",
        "model.add_loss(loss)\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam')\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor = 'loss', patience = 3, mode = 'min') # for early stopping\n",
        "\n",
        "history = model.fit(\n",
        "    x_train,\n",
        "    batch_size = 100,\n",
        "    epochs=epochs, verbose=True, callbacks = [callback], validation_split = 0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CDx41eqJCr1",
        "outputId": "fd58e208-5eeb-43f3-8699-a0d0f7523874"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "56/56 [==============================] - 20s 66ms/step - loss: 0.3118 - val_loss: 0.0500\n",
            "Epoch 2/25\n",
            "56/56 [==============================] - 3s 54ms/step - loss: 0.0526 - val_loss: 0.0500\n",
            "Epoch 3/25\n",
            "56/56 [==============================] - 3s 54ms/step - loss: 0.0504 - val_loss: 0.0500\n",
            "Epoch 4/25\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.0501 - val_loss: 0.0500\n",
            "Epoch 5/25\n",
            "56/56 [==============================] - 3s 56ms/step - loss: 0.0501 - val_loss: 0.0500\n",
            "Epoch 6/25\n",
            "56/56 [==============================] - 4s 79ms/step - loss: 0.0500 - val_loss: 0.0500\n",
            "Epoch 7/25\n",
            "56/56 [==============================] - 3s 60ms/step - loss: 0.0500 - val_loss: 0.0500\n",
            "Epoch 8/25\n",
            "56/56 [==============================] - 3s 49ms/step - loss: 0.0500 - val_loss: 0.0500\n",
            "Epoch 9/25\n",
            "56/56 [==============================] - 3s 46ms/step - loss: 0.0500 - val_loss: 0.0500\n",
            "Epoch 10/25\n",
            "56/56 [==============================] - 3s 46ms/step - loss: 0.0500 - val_loss: 0.0500\n",
            "Epoch 11/25\n",
            "56/56 [==============================] - 3s 46ms/step - loss: 0.0495 - val_loss: 0.0482\n",
            "Epoch 12/25\n",
            "56/56 [==============================] - 3s 46ms/step - loss: 0.0449 - val_loss: 0.0413\n",
            "Epoch 13/25\n",
            "56/56 [==============================] - 2s 44ms/step - loss: 0.0368 - val_loss: 0.0312\n",
            "Epoch 14/25\n",
            "56/56 [==============================] - 3s 47ms/step - loss: 0.0320 - val_loss: 0.0309\n",
            "Epoch 15/25\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.0285 - val_loss: 0.0329\n",
            "Epoch 16/25\n",
            "56/56 [==============================] - 3s 50ms/step - loss: 0.0242 - val_loss: 0.0411\n",
            "Epoch 17/25\n",
            "56/56 [==============================] - 2s 44ms/step - loss: 0.0218 - val_loss: 0.0330\n",
            "Epoch 18/25\n",
            "56/56 [==============================] - 3s 50ms/step - loss: 0.0199 - val_loss: 0.0201\n",
            "Epoch 19/25\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.0199 - val_loss: 0.0174\n",
            "Epoch 20/25\n",
            "56/56 [==============================] - 3s 47ms/step - loss: 0.0185 - val_loss: 0.0174\n",
            "Epoch 21/25\n",
            "56/56 [==============================] - 3s 50ms/step - loss: 0.0190 - val_loss: 0.0267\n",
            "Epoch 22/25\n",
            "56/56 [==============================] - 2s 44ms/step - loss: 0.0173 - val_loss: 0.0147\n",
            "Epoch 23/25\n",
            "56/56 [==============================] - 3s 47ms/step - loss: 0.0166 - val_loss: 0.0501\n",
            "Epoch 24/25\n",
            "56/56 [==============================] - 3s 47ms/step - loss: 0.0165 - val_loss: 0.0266\n",
            "Epoch 25/25\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.0164 - val_loss: 0.0193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ploting \n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "\n",
        "plt.legend(['loss', 'val_loss'])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "UAknrzpQKioG",
        "outputId": "5aff9fc9-7252-4f39-ef55-ed37fa25ae35"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predictions\n",
        "x_predict = embedding_model.predict(x_latent)\n",
        "g_predict = embedding_model.predict(g_latent)\n",
        "t_predict = embedding_model.predict(tx_latent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihCMEJnRKp9N",
        "outputId": "37c0c10a-9d3f-4306-9931-34cd304b98a5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47/47 [==============================] - 1s 8ms/step\n",
            "4/4 [==============================] - 0s 37ms/step\n",
            "13/13 [==============================] - 0s 10ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# saving siamese predictions\n",
        "np.savez_compressed(\"/content/drive/MyDrive/light_on_siamese_0.npz\", x_predict = x_predict, g_predict = g_predict, t_predict = t_predict, ty = ty, i = i, gi = gi, ti = ti)"
      ],
      "metadata": {
        "id": "3FH4WNAoLhUV"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zWjVCfNML0tA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}